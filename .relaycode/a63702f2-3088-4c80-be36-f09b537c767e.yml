uuid: a63702f2-3088-4c80-be36-f09b537c767e
projectId: relaycode
createdAt: '2025-06-24T06:55:37.017Z'
gitCommitMsg: 'refactor: Improve DRYness and maintainability across core modules'
promptSummary: >-
  Refactor the codebase to be significantly more DRY and maintainable by
  cleaning up config loading, standardizing response parsing, and improving file
  system utilities, all without causing regressions.
reasoning:
  - >-
    I've analyzed your codebase to identify areas where we can significantly
    improve code duplication and clarity, adhering to the DRY (Don't Repeat
    Yourself) principle. My plan involves targeted refactoring in three core
    files to make the logic more streamlined, reusable, and maintainable,
    without affecting any existing features.
  - '### 1. Simplify Configuration Loading (`src/core/config.ts`)'
  - >-
    To clean up the `findConfig` function, I'll extract the complex logic for
    loading and transpiling `.ts` and `.js` configuration files into a new,
    self-contained helper function called `loadModuleConfig`. This will make the
    main `findConfig` function much easier to read and understand, as its sole
    responsibility will be to orchestrate finding the config path and then
    delegating the loading to the appropriate handler (JSON or module).
  - '### 2. Refactor and Standardize Response Parsing (`src/core/parser.ts`)'
  - >-
    In the LLM response parser, I'll refactor the `extractCodeBetweenMarkers`
    function to be more readable and correct. The new version will handle
    content normalization (trimming, line endings) more consistently.
    Subsequently, I will simplify the logic in `parseCodeBlock` to use this
    improved function unconditionally, removing a conditional check and ensuring
    all file content is processed the same way. This improves robustness and
    makes the code cleaner.
  - '### 3. Enhance and Reuse File Deletion Logic (`src/core/executor.ts`)'
  - >-
    I'll improve the `deleteFile` utility to be more robust by handling
    `ENOTDIR` errors, which can occur during rollbacks. This enhanced utility
    will then be used within the `restoreSnapshot` function, replacing a block
    of nested `try-catch` logic. This change not only makes `deleteFile` more
    reliable but also simplifies the `restoreSnapshot` implementation by reusing
    existing code.
  - >-
    These changes collectively make the codebase significantly more DRY and
    maintainable while preserving all functionality.
operations:
  - type: write
    path: src/core/config.ts
    content: >-
      --- src/core/config.ts

      +++ src/core/config.ts

      @@ -19,6 +19,34 @@
         return null;
       };
       
      +const loadModuleConfig = async (configPath: string):
      Promise<RelayCodeConfigInput> => {

      +  let importPath = configPath;

      +  let tempDir: string | null = null;

      +

      +  if (configPath.endsWith('.ts')) {

      +    tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'relaycode-'));

      +    const tempFile = path.join(tempDir, 'relaycode.config.mjs');

      +

      +    await build({

      +      entryPoints: [configPath],

      +      outfile: tempFile,

      +      bundle: true,

      +      platform: 'node',

      +      format: 'esm',

      +      alias: {

      +        'relaycode': path.resolve(process.cwd(), 'src/index.ts')

      +      },

      +    });

      +    importPath = tempFile;

      +  }

      +

      +  try {

      +    const module = await import(`${importPath}?t=${Date.now()}`);

      +    return module.default;

      +  } finally {

      +    if (tempDir) await fs.rm(tempDir, { recursive: true, force: true });

      +  }

      +};

      +
       export const findConfig = async (cwd: string = process.cwd()): Promise<Config | null> => {
         const configPath = await findConfigPath(cwd);
         if (!configPath) {
      @@ -30,41 +58,7 @@
             const fileContent = await fs.readFile(configPath, 'utf-8');
             configJson = JSON.parse(fileContent);
           } else { // Handle .ts or .js config
      -      let importPath = configPath;

      -      let tempDir: string | null = null;

      -

      -      // If it's a TypeScript file, we need to transpile it to JS first.

      -      if (configPath.endsWith('.ts')) {

      -        tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'relaycode-'));

      -        const tempFile = path.join(tempDir, 'relaycode.config.mjs');

      -

      -        await build({

      -          entryPoints: [configPath],

      -          outfile: tempFile,

      -          bundle: true,

      -          platform: 'node',

      -          format: 'esm',

      -          // We bundle all dependencies into the temp file to avoid
      module resolution

      -          // issues when node executes the config from the /tmp
      directory.

      -          alias: {

      -            'relaycode': path.resolve(process.cwd(), 'src/index.ts')

      -          },

      -        });

      -

      -        importPath = tempFile;

      -      }

      -

      -      try {

      -        // Use dynamic import with a cache-busting query parameter

      -        const module = await import(`${importPath}?t=${Date.now()}`);

      -        configJson = module.default;

      -      } finally {

      -        // Clean up the temporary directory if it was created

      -        if (tempDir) {

      -          await fs.rm(tempDir, { recursive: true, force: true });

      -        }

      -      }

      +      configJson = await loadModuleConfig(configPath);
           }
           return ConfigSchema.parse(configJson);
         } catch (error) {
    patchStrategy: new-unified
  - type: write
    path: src/core/parser.ts
    content: >-
      --- src/core/parser.ts

      +++ src/core/parser.ts

      @@ -19,17 +19,14 @@
       
       const extractCodeBetweenMarkers = (content: string): string => {
           const startMarkerIndex = content.indexOf(CODE_BLOCK_START_MARKER);
      -    const endMarkerIndex = content.lastIndexOf(CODE_BLOCK_END_MARKER);

      -

      -    if (startMarkerIndex === -1 || endMarkerIndex === -1 ||
      endMarkerIndex <= startMarkerIndex) {

      -        // Normalize line endings to Unix-style \n for consistency

      -        return content.trim().replace(/\r\n/g, '\n');

      +    const endMarkerIndex =
      content.lastIndexOf(CODE_BLOCK_END_MARKER);    

      +    

      +    let relevantContent = content;

      +    if (startMarkerIndex !== -1 && endMarkerIndex !== -1 &&
      endMarkerIndex > startMarkerIndex) {

      +        relevantContent = content.substring(startMarkerIndex +
      CODE_BLOCK_START_MARKER.length, endMarkerIndex);
           }
      -

      -    const startIndex = startMarkerIndex + CODE_BLOCK_START_MARKER.length;

      -    // Normalize line endings to Unix-style \n for consistency

      -    return content.substring(startIndex,
      endMarkerIndex).trim().replace(/\r\n/g, '\n');

      +    

      +    return relevantContent.trim().replace(/\r\n/g, '\n');
       };
       
       const parseCodeBlockHeader = (headerLine: string): ParsedHeader | null => {
      @@ -141,10 +138,10 @@
           }
       
           const patchStrategy = inferPatchStrategy(content, parsedHeader.patchStrategy);
      -    const cleanContent = content.includes(CODE_BLOCK_START_MARKER) ?
      extractCodeBetweenMarkers(content) : content;

      +    const cleanContent = extractCodeBetweenMarkers(content);
       
           return {
      -        operation: { type: 'write', path: filePath, content:
      cleanContent, patchStrategy },

      +        operation: { type: 'write', path: filePath, content:
      cleanContent, patchStrategy }, 
               fullMatch
           };
       };
    patchStrategy: new-unified
  - type: write
    path: src/core/executor.ts
    content: >-
      <<<<<<< SEARCH

      export const deleteFile = async (filePath: string, cwd: string =
      process.cwd()): Promise<void> => {
        try {
          await fs.unlink(path.resolve(cwd, filePath));
        } catch (error) {
          if (isEnoentError(error)) {
            // File already deleted, which is fine.
            return;
          }
          throw error;
        }
      };

      =======

      export const deleteFile = async (filePath: string, cwd: string =
      process.cwd()): Promise<void> => {
        try {
          await fs.unlink(path.resolve(cwd, filePath));
        } catch (error) {
          if (error instanceof Error && 'code' in error && (error.code === 'ENOENT' || error.code === 'ENOTDIR')) {
            // File already deleted or is a directory, which is fine for an unlink operation.
            return;
          }
          throw error;
        }
      };

      >>>>>>> REPLACE

      <<<<<<< SEARCH
              if (content === null) {
                // If the file didn't exist in the snapshot, make sure it doesn't exist after restore.
                try {
                  await fs.unlink(fullPath);
                  directoriesToClean.add(path.dirname(fullPath));
                } catch (unlinkError) {
                    if (unlinkError instanceof Error && 'code' in unlinkError && (unlinkError.code === 'ENOENT' || unlinkError.code === 'ENOTDIR')) {
                        // This is fine, file is already gone.
                    } else {
                        throw unlinkError; // This is a real error.
                    }
                }
              } else {
      =======
              if (content === null) {
                // If the file didn't exist in the snapshot, make sure it doesn't exist after restore.
                await deleteFile(filePath, cwd);
                directoriesToClean.add(path.dirname(fullPath));
              } else {
      >>>>>>> REPLACE
    patchStrategy: multi-search-replace
snapshot:
  src/core/config.ts: >
    import { z } from 'zod';

    import path from 'path';

    import { promises as fs } from 'fs';

    import { build } from 'esbuild';

    import os from 'os';

    import { Config, ConfigSchema, RelayCodeConfigInput } from '../types';

    import { CONFIG_FILE_NAMES, STATE_DIRECTORY_NAME, CONFIG_FILE_NAME_TS } from
    '../utils/constants';

    import { logger, isEnoentError } from '../utils/logger';

    import chalk from 'chalk';


    export const findConfigPath = async (cwd: string = process.cwd()):
    Promise<string | null> => {
      for (const fileName of CONFIG_FILE_NAMES) {
        const configPath = path.join(cwd, fileName);
        try {
          await fs.access(configPath);
          return configPath;
        } catch (error) {
          if (!isEnoentError(error)) {
            // ignore other errors for now to keep searching
          }
        }
      }
      return null;
    };


    export const findConfig = async (cwd: string = process.cwd()):
    Promise<Config | null> => {
      const configPath = await findConfigPath(cwd);
      if (!configPath) {
        return null;
      }
      try {
        let configJson: RelayCodeConfigInput;
        if (configPath.endsWith('.json')) { // Handle JSON config
          const fileContent = await fs.readFile(configPath, 'utf-8');
          configJson = JSON.parse(fileContent);
        } else { // Handle .ts or .js config
          let importPath = configPath;
          let tempDir: string | null = null;

          // If it's a TypeScript file, we need to transpile it to JS first.
          if (configPath.endsWith('.ts')) {
            tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'relaycode-'));
            const tempFile = path.join(tempDir, 'relaycode.config.mjs');

            await build({
              entryPoints: [configPath],
              outfile: tempFile,
              bundle: true,
              platform: 'node',
              format: 'esm',
              // We bundle all dependencies into the temp file to avoid module resolution
              // issues when node executes the config from the /tmp directory.
              alias: {
                'relaycode': path.resolve(process.cwd(), 'src/index.ts')
              },
            });

            importPath = tempFile;
          }

          try {
            // Use dynamic import with a cache-busting query parameter
            const module = await import(`${importPath}?t=${Date.now()}`);
            configJson = module.default;
          } finally {
            // Clean up the temporary directory if it was created
            if (tempDir) {
              await fs.rm(tempDir, { recursive: true, force: true });
            }
          }
        }
        return ConfigSchema.parse(configJson);
      } catch (error) {
        if (isEnoentError(error)) {
          return null;
        }
        if (error instanceof z.ZodError) {
          throw new Error(`Invalid configuration in ${path.basename(configPath)}: ${error.message}`);
        }
        throw error;
      }
    };


    export const loadConfigOrExit = async (cwd: string = process.cwd()):
    Promise<Config> => {
      const config = await findConfig(cwd);
      if (!config) {
        logger.error(`Configuration file ('${chalk.cyan('relaycode.config.ts')}', '.js', or '.json') not found.`);
        logger.info(`Please run ${chalk.magenta("'relay init'")} to create one.`);
        process.exit(1);
      }
      return config;
    };


    export const createConfig = async (projectId: string, cwd: string =
    process.cwd()): Promise<Config> => {
      const config: RelayCodeConfigInput = { projectId };

      // Ensure the schema defaults are applied for nested objects
      const validatedConfig = ConfigSchema.parse(config);

      const tsConfigContent = `import { defineConfig } from 'relaycode';

    export default defineConfig(${JSON.stringify({ projectId }, null, 2)});

    `;

      const configPath = path.join(cwd, CONFIG_FILE_NAME_TS);
      await fs.writeFile(configPath, tsConfigContent);

      return validatedConfig;
    };


    export const ensureStateDirExists = async (cwd: string = process.cwd()):
    Promise<void> => {
      const stateDirPath = path.join(cwd, STATE_DIRECTORY_NAME);
      await fs.mkdir(stateDirPath, { recursive: true });
    };


    export const getProjectId = async (cwd: string = process.cwd()):
    Promise<string> => {
      try {
        const pkgJsonPath = path.join(cwd, 'package.json');
        const fileContent = await fs.readFile(pkgJsonPath, 'utf-8');
        const pkgJson = JSON.parse(fileContent);
        if (pkgJson.name && typeof pkgJson.name === 'string') {
          return pkgJson.name;
        }
      } catch (e) {
        // Ignore if package.json doesn't exist or is invalid
      }
      return path.basename(cwd);
    };
  src/core/parser.ts: >-
    import yaml from 'js-yaml';

    import { z } from 'zod';

    import {
        ControlYamlSchema,
        FileOperation,
        ParsedLLMResponse,
        ParsedLLMResponseSchema,
        PatchStrategy,
        PatchStrategySchema,
    } from '../types';

    import {
        CODE_BLOCK_START_MARKER,
        CODE_BLOCK_END_MARKER,
        DELETE_FILE_MARKER,
        RENAME_FILE_OPERATION
    } from '../utils/constants';

    import { getErrorMessage, logger } from '../utils/logger';


    const CODE_BLOCK_REGEX =
    /```(?:\w+)?(?:\s*\/\/\s*(.*?)|\s+(.*?))?[\r\n]([\s\S]*?)[\r\n]```/g;

    const YAML_BLOCK_REGEX = /```yaml[\r\n]([\s\S]+?)```/;


    type ParsedHeader = {
        filePath: string;
        patchStrategy: PatchStrategy | null;
    };


    const extractCodeBetweenMarkers = (content: string): string => {
        const startMarkerIndex = content.indexOf(CODE_BLOCK_START_MARKER);
        const endMarkerIndex = content.lastIndexOf(CODE_BLOCK_END_MARKER);

        if (startMarkerIndex === -1 || endMarkerIndex === -1 || endMarkerIndex <= startMarkerIndex) {
            // Normalize line endings to Unix-style \n for consistency
            return content.trim().replace(/\r\n/g, '\n');
        }

        const startIndex = startMarkerIndex + CODE_BLOCK_START_MARKER.length;
        // Normalize line endings to Unix-style \n for consistency
        return content.substring(startIndex, endMarkerIndex).trim().replace(/\r\n/g, '\n');
    };


    const parseCodeBlockHeader = (headerLine: string): ParsedHeader | null => {
        const quotedMatch = headerLine.match(/^"(.+?)"(?:\s+(.*))?$/);
        if (quotedMatch) {
            const filePath = quotedMatch[1]!;
            const strategyStr = (quotedMatch[2] || '').trim();
            if (strategyStr) {
                const parsedStrategy = PatchStrategySchema.safeParse(strategyStr);
                if (!parsedStrategy.success) {
                    logger.debug(`Invalid patch strategy for quoted path: ${strategyStr}`);
                    return null;
                }
                return { filePath, patchStrategy: parsedStrategy.data };
            }
            return { filePath, patchStrategy: null };
        }

        const parts = headerLine.split(/\s+/);
        if (parts.length === 1 && parts[0]) {
            return { filePath: parts[0], patchStrategy: null };
        }
        if (parts.length === 2 && parts[0] && parts[1]) {
            const parsedStrategy = PatchStrategySchema.safeParse(parts[1]);
            if (parsedStrategy.success) {
                return { filePath: parts[0], patchStrategy: parsedStrategy.data };
            } else {
                logger.debug(`Treating entire header as file path since second word is not a valid strategy: "${headerLine}"`);
                return { filePath: headerLine, patchStrategy: null };
            }
        }

        if (parts.length > 2) {
            logger.debug(`Skipping unquoted header with more than 2 words: "${headerLine}"`);
            return null;
        }

        return null; // For empty or invalid header
    };


    const inferPatchStrategy = (content: string, providedStrategy: PatchStrategy
    | null): PatchStrategy => {
        if (providedStrategy) return providedStrategy;
        if (/^<<<<<<< SEARCH\s*$/m.test(content) && content.includes('>>>>>>> REPLACE')) return 'multi-search-replace';
        if (content.startsWith('--- ') && content.includes('+++ ') && content.includes('@@')) return 'new-unified';
        return 'replace';
    };


    const extractAndParseYaml = (rawText: string) => {
        const yamlBlockMatch = rawText.match(YAML_BLOCK_REGEX);
        let yamlText: string | null = null;
        let textWithoutYaml = rawText;

        if (yamlBlockMatch?.[1]) {
            yamlText = yamlBlockMatch[1];
            textWithoutYaml = rawText.replace(YAML_BLOCK_REGEX, '').trim();
        } else {
            const lines = rawText.trim().split('\n');
            let yamlStartIndex = -1;
            const searchLimit = Math.max(0, lines.length - 20);
            for (let i = lines.length - 1; i >= searchLimit; i--) {
                if (lines[i]?.trim().match(/^projectId:\s*['"]?[\w.-]+['"]?$/)) {
                    yamlStartIndex = i;
                    break;
                }
            }

            if (yamlStartIndex !== -1) {
                yamlText = lines.slice(yamlStartIndex).join('\n');
                textWithoutYaml = lines.slice(0, yamlStartIndex).join('\n').trim();
            }
        }

        if (!yamlText) return { control: null, textWithoutYaml: rawText };

        try {
            const yamlContent = yaml.load(yamlText);
            const control = ControlYamlSchema.parse(yamlContent);
            return { control, textWithoutYaml };
        } catch (e) {
            logger.debug(`Error parsing YAML or control schema: ${getErrorMessage(e)}`);
            return { control: null, textWithoutYaml: rawText };
        }
    };


    const parseCodeBlock = (match: RegExpExecArray): { operation: FileOperation,
    fullMatch: string } | null => {
        const [fullMatch, commentHeaderLine, spaceHeaderLine, rawContent] = match;
        const headerLine = (commentHeaderLine || spaceHeaderLine || '').trim();
        const content = (rawContent || '').trim();

        if (!headerLine) return null;

        if (headerLine === RENAME_FILE_OPERATION) {
            try {
                const { from, to } = z.object({ from: z.string().min(1), to: z.string().min(1) }).parse(JSON.parse(content));
                return { operation: { type: 'rename', from, to }, fullMatch };
            } catch (e) {
                logger.debug(`Invalid rename operation content: ${getErrorMessage(e)}`);
                return null;
            }
        }

        const parsedHeader = parseCodeBlockHeader(headerLine);
        if (!parsedHeader) {
            logger.debug(`Could not parse header: ${headerLine}`);
            return null;
        }

        const { filePath } = parsedHeader;

        if (content === DELETE_FILE_MARKER) {
            return { operation: { type: 'delete', path: filePath }, fullMatch };
        }

        const patchStrategy = inferPatchStrategy(content, parsedHeader.patchStrategy);
        const cleanContent = content.includes(CODE_BLOCK_START_MARKER) ? extractCodeBetweenMarkers(content) : content;

        return {
            operation: { type: 'write', path: filePath, content: cleanContent, patchStrategy },
            fullMatch
        };
    };


    export const parseLLMResponse = (rawText: string): ParsedLLMResponse | null
    => {
        logger.debug('Parsing LLM response...');
        const { control, textWithoutYaml } = extractAndParseYaml(rawText);

        if (!control) {
            logger.debug('Could not parse control YAML from response.');
            return null;
        }

        const operations: FileOperation[] = [];
        const matchedBlocks: string[] = [];
        let match;

        while ((match = CODE_BLOCK_REGEX.exec(textWithoutYaml)) !== null) {
            const result = parseCodeBlock(match);
            if (result) {
                operations.push(result.operation);
                matchedBlocks.push(result.fullMatch);
            }
        }

        if (operations.length === 0) {
            logger.debug('No valid operations found in response.');
            return null;
        }

        let reasoningText = textWithoutYaml;
        for (const block of matchedBlocks) {
            reasoningText = reasoningText.replace(block, '');
        }
        const reasoning = reasoningText.split('\n').map(line => line.trim()).filter(Boolean);

        try {
            const parsedResponse = ParsedLLMResponseSchema.parse({ control, operations, reasoning });
            logger.debug('Successfully parsed LLM response.');
            return parsedResponse;
        } catch (e) {
            logger.debug(`Final validation failed: ${getErrorMessage(e)}`);
            return null;
        }
    };
  src/core/executor.ts: >-
    import { promises as fs } from 'fs';

    import path from 'path';

    import { FileOperation, FileSnapshot } from '../types';

    import { newUnifiedDiffStrategyService, multiSearchReplaceService,
    unifiedDiffService } from 'diff-apply';

    import { getErrorMessage, isEnoentError } from '../utils/logger';


    const patchStrategies = {
      'new-unified': (p: { originalContent: string; diffContent: string; }) => {
        const service = newUnifiedDiffStrategyService.newUnifiedDiffStrategyService.create(0.95);
        return service.applyDiff(p);
      },
      'multi-search-replace': (p: { originalContent: string; diffContent: string; }) => {
        return multiSearchReplaceService.multiSearchReplaceService.applyDiff(p);
      },
      'unified': (p: { originalContent: string; diffContent: string; }) => {
        return unifiedDiffService.unifiedDiffService.applyDiff(p.originalContent, p.diffContent);
      },
    };


    export const readFileContent = async (filePath: string, cwd: string =
    process.cwd()): Promise<string | null> => {
      try {
        return await fs.readFile(path.resolve(cwd, filePath), 'utf-8');
      } catch (error) {
        if (isEnoentError(error)) {
          return null; // File doesn't exist
        }
        throw error;
      }
    };


    export const writeFileContent = async (filePath: string, content: string,
    cwd: string = process.cwd()): Promise<void> => {
      const absolutePath = path.resolve(cwd, filePath);
      await fs.mkdir(path.dirname(absolutePath), { recursive: true });
      await fs.writeFile(absolutePath, content, 'utf-8');
    };


    export const deleteFile = async (filePath: string, cwd: string =
    process.cwd()): Promise<void> => {
      try {
        await fs.unlink(path.resolve(cwd, filePath));
      } catch (error) {
        if (isEnoentError(error)) {
          // File already deleted, which is fine.
          return;
        }
        throw error;
      }
    };


    export const fileExists = async (filePath: string, cwd: string =
    process.cwd()): Promise<boolean> => {
      try {
        await fs.access(path.resolve(cwd, filePath));
        return true;
      } catch {
        return false;
      }
    };


    export const safeRename = async (fromPath: string, toPath:string):
    Promise<void> => {
        try {
            await fs.rename(fromPath, toPath);
        } catch (error) {
            if (error instanceof Error && 'code' in error && error.code === 'EXDEV') {
                await fs.copyFile(fromPath, toPath);
                await fs.unlink(fromPath);
            } else {
                throw error;
            }
        }
    };


    export const renameFile = async (fromPath: string, toPath: string, cwd:
    string = process.cwd()): Promise<void> => {
      const fromAbsolutePath = path.resolve(cwd, fromPath);
      const toAbsolutePath = path.resolve(cwd, toPath);
      await fs.mkdir(path.dirname(toAbsolutePath), { recursive: true });
      await safeRename(fromAbsolutePath, toAbsolutePath);
    };


    export const createSnapshot = async (filePaths: string[], cwd: string =
    process.cwd()): Promise<FileSnapshot> => {
      const snapshot: FileSnapshot = {};
      await Promise.all(
        filePaths.map(async (filePath) => {
          snapshot[filePath] = await readFileContent(filePath, cwd);
        })
      );
      return snapshot;
    };


    export const applyOperations = async (operations: FileOperation[], cwd:
    string = process.cwd()): Promise<Map<string, string>> => {
      const newContents = new Map<string, string>();
      // Operations must be applied sequentially to ensure that if one fails,
      // we can roll back from a known state.
      for (const op of operations) {
        if (op.type === 'delete') {
          await deleteFile(op.path, cwd);
          continue;
        }
        if (op.type === 'rename') {
          await renameFile(op.from, op.to, cwd);
          continue;
        }
        
        let finalContent: string;

        if (op.patchStrategy === 'replace') {
          finalContent = op.content;
        } else {
          // For patch strategies, apply them sequentially
          const originalContent = await readFileContent(op.path, cwd);
          if (originalContent === null && op.patchStrategy === 'multi-search-replace') {
            throw new Error(`Cannot use 'multi-search-replace' on a new file: ${op.path}`);
          }

          try {
            const diffParams = {
              originalContent: originalContent ?? '',
              diffContent: op.content,
            };
            
            const patcher = patchStrategies[op.patchStrategy as keyof typeof patchStrategies];
            if (!patcher) {
              throw new Error(`Unknown patch strategy: ${op.patchStrategy}`);
            }
            
            const result = await patcher(diffParams);
            if (result.success) {
              finalContent = result.content;
            } else {
              throw new Error(result.error);
            }
          } catch (e) {
            throw new Error(`Error applying patch for ${op.path} with strategy '${op.patchStrategy}': ${getErrorMessage(e)}`);
          }
        }
        
        await writeFileContent(op.path, finalContent, cwd);
        newContents.set(op.path, finalContent);
      }
      return newContents;
    };


    // Helper to check if a directory is empty

    const isDirectoryEmpty = async (dirPath: string): Promise<boolean> => {
      try {
        const files = await fs.readdir(dirPath);
        return files.length === 0;
      } catch (error) {
        // If directory doesn't exist or is not accessible, consider it "not empty"
        return false;
      }
    };


    // Recursively remove all empty parent directories up to a limit

    const removeEmptyParentDirectories = async (dirPath: string, rootDir:
    string): Promise<void> => {
      if (!dirPath.startsWith(rootDir) || dirPath === rootDir) {
        return;
      }
      
      try {
        const isEmpty = await isDirectoryEmpty(dirPath);
        if (isEmpty) {
          await fs.rmdir(dirPath);
          // Recursively check parent directory
          await removeEmptyParentDirectories(path.dirname(dirPath), rootDir);
        }
      } catch (error) {
        // Ignore directory removal errors, but don't continue up the chain
        if (!(error instanceof Error && 'code' in error &&
            (error.code === 'ENOENT' || error.code === 'ENOTDIR'))) {
          console.warn(`Failed to clean up directory ${dirPath}:`, getErrorMessage(error));
        }
      }
    };


    export const restoreSnapshot = async (snapshot: FileSnapshot, cwd: string =
    process.cwd()): Promise<void> => {
      const projectRoot = path.resolve(cwd);
      const entries = Object.entries(snapshot);
      const directoriesToClean = new Set<string>();
      const restoreErrors: { path: string, error: unknown }[] = [];

      // Attempt to restore all files in parallel, collecting errors.
      await Promise.all(entries.map(async ([filePath, content]) => {
          const fullPath = path.resolve(cwd, filePath);
          try {
            if (content === null) {
              // If the file didn't exist in the snapshot, make sure it doesn't exist after restore.
              try {
                await fs.unlink(fullPath);
                directoriesToClean.add(path.dirname(fullPath));
              } catch (unlinkError) {
                  if (unlinkError instanceof Error && 'code' in unlinkError && (unlinkError.code === 'ENOENT' || unlinkError.code === 'ENOTDIR')) {
                      // This is fine, file is already gone.
                  } else {
                      throw unlinkError; // This is a real error.
                  }
              }
            } else {
              // Create directory structure if needed and write the original content back.
              await fs.mkdir(path.dirname(fullPath), { recursive: true });
              await fs.writeFile(fullPath, content, 'utf-8');
            }
          } catch (error) {
            restoreErrors.push({ path: filePath, error });
          }
      }));
      
      // After all files are processed, clean up empty directories
      // Sort directories by depth (deepest first) to clean up nested empty dirs properly
      const sortedDirs = Array.from(directoriesToClean)
        .sort((a, b) => b.split(path.sep).length - a.split(path.sep).length);
      
      // Process each directory that had files deleted
      for (const dir of sortedDirs) {
        await removeEmptyParentDirectories(dir, projectRoot);
      }

      if (restoreErrors.length > 0) {
        const errorSummary = restoreErrors
          .map(e => `  - ${e.path}: ${getErrorMessage(e.error)}`)
          .join('\n');
        throw new Error(`Rollback failed for ${restoreErrors.length} file(s):\n${errorSummary}`);
      }
    };
approved: true
